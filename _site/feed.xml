<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>BADBYE</title>
		<description>Welcome to my blog!</description>
		<link>http://badbye.github.io/badbye.github.com</link>
		<atom:link href="http://badbye.github.io/badbye.github.com/feed.xml" rel="self" type="application/rss+xml" />
		
			<item>
				<title>Rmd到PDF的转换</title>
				<description>&lt;p&gt;对于用惯了Word的来说，Latex大概是一个噩梦，好在能用惯Word的人并不多。各位观众应该都或多或少的见过各种Word排版技巧充斥在朋友圈，人人网，QQ空间等。跟Latex的命令一样，让人看了就头疼。&lt;/p&gt;

&lt;p&gt;如果你会用Knitr，那就一定也会用Markdown(二者都不会的看官请移步&lt;a href=&quot;http://cos.name/2012/06/reproducible-research-with-knitr/&quot;&gt;这里&lt;/a&gt;)。Markdown是HTML的简化，语法简洁，十分钟就能学完。只是Knitr初出之时，Markdown也就只能转成HTML而已。如今Knitr已3岁有余，从Markdown到PDF的转化也很成熟了。话不多说，让我们直奔主题。&lt;/p&gt;

&lt;h2 id=&quot;预先安装&quot;&gt;预先安装&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;最新版本的Rstudio(已经内置的Pandoc工具，没听说过这个工具也没关系，装上最新版的Rstudio就是了)。&lt;/li&gt;
&lt;li&gt;R包：&lt;code&gt;knitr&lt;/code&gt;，&lt;code&gt;rmarkdown&lt;/code&gt;，均可从CRAN上直接下载。&lt;/li&gt;
&lt;li&gt;Tex环境。Windows用户安装CTEX，Linux用户安装Texlive，Mac用户安装MacTex。似乎各种版本都有精简版和完整版，建议安装完整版。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;英文环境&quot;&gt;英文环境&lt;/h2&gt;

&lt;p&gt;新建一个Rmd文档，其头文件应该是以下这种格式：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;o&quot;&gt;---&lt;/span&gt;
title&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;XXX&amp;quot;&lt;/span&gt;
author&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;xxx&amp;quot;&lt;/span&gt;
&lt;span class=&quot;kp&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;xxx&amp;quot;&lt;/span&gt;
output&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; html_document
&lt;span class=&quot;o&quot;&gt;---&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如果你的Rmd文档是全英的，只需要把&lt;code&gt;html_document&lt;/code&gt;改成&lt;code&gt;pdf_document&lt;/code&gt;。Ctrl+S保存后，编译按钮会自动从&lt;code&gt;Knit HTML&lt;/code&gt;变成&lt;code&gt;Knit PDF&lt;/code&gt;，轻点鼠标即大功告成。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://badbye.github.io/images/knit.png&quot; alt=&quot;knit&quot;&gt;&lt;/p&gt;

&lt;p&gt;这里简单说下转换的流程是：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;knitr运行Rmd中的代码，生成md文件&lt;/li&gt;
&lt;li&gt;神器Pandoc把md文件转化为tex文件&lt;/li&gt;
&lt;li&gt;Latex环境编译tex文件生产PDF&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;中文环境&quot;&gt;中文环境&lt;/h2&gt;

&lt;p&gt;如果Rmd文档中有中文字符，那你就呵呵了。因为在第二步md到tex的转化中，是按照预先设置的模板来的，而默认的模板中并没有设置中文字体。&lt;/p&gt;

&lt;p&gt;如果你是Latex和Padoc的高手，折腾一下模板就能搞定了。初学者也不用紧张，已经有高手把模板封装打包了，只需安装&lt;a href=&quot;https://github.com/rstudio/rticles&quot;&gt;&lt;code&gt;rticles&lt;/code&gt;&lt;/a&gt;这个包即可：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;devtools&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;install_github&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;rstudio/rticles&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;安装完成后，新建一个Rmd文件，从模板中选择&lt;code&gt;CTex Documents&lt;/code&gt;：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://badbye.github.io/images/ctex.png&quot; alt=&quot;ctex&quot;&gt;&lt;/p&gt;

&lt;p&gt;可以看到，&lt;code&gt;rticles&lt;/code&gt;还提供了其他的模板如&lt;code&gt;ACM&lt;/code&gt;，&lt;code&gt;ACS&lt;/code&gt;和&lt;code&gt;Journal of Statistical Software&lt;/code&gt;等。没错，以后要投稿这些期刊的话，你可以直接用Markdown的语法来写了！回到&lt;code&gt;CTex Documents&lt;/code&gt;模板中来，作者已经里边阐述了各系统下Rmd到PDF的转化问题。如果你是Windows用户，轻点鼠标即可生产精致的PDF文件。如果你是Linux或者Mac用户，只能无奈的再次呵呵了。不过别急着丧气，读读模板中的内容，其中已有妙计相赠。&lt;/p&gt;

&lt;h2 id=&quot;其他&quot;&gt;其他&lt;/h2&gt;

&lt;p&gt;(1)对于其他的Rmd文档，想转成PDF的话，只需要把&lt;code&gt;CTex Documents&lt;/code&gt;模板中的头信息粘贴过去，修改其中的title和author信息即可。&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;o&quot;&gt;---&lt;/span&gt;
title&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;在R Markdown文档中使用中文&amp;quot;&lt;/span&gt;
author&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; 谢益辉
  &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; 邱怡轩
  &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; 于淼
documentclass&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; ctexart
output&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
  pdf_document&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
    fig_caption&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; yes
    latex_engine&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; xelatex
    number_sections&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; yes
    template&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;expr rticles&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;ctex_template&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    toc&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; yes
classoption&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;hyperref`r if (.Platform$OS.type != &amp;#39;windows&amp;#39;) &amp;#39;,nofonts&amp;#39;`&amp;quot;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;---&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;(2)按钮&lt;code&gt;Knitr PDF&lt;/code&gt;背后所做的事是由&lt;code&gt;rmarkdown&lt;/code&gt;包的&lt;code&gt;render&lt;/code&gt;函数支持的，相应的代码是：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;rmarkdown&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;render&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;toremove.Rmd&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; pdf_document&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如果有多个文档，写个脚本就能把整个流程完全自动化了。&lt;/p&gt;

&lt;p&gt;(3)如果Markdown中包含HTML标签，输出HTML是毫无影响的。比如&lt;code&gt;&amp;lt;img src=picture.png/&amp;gt;&lt;/code&gt;与&lt;code&gt;![pic](picture.png)&lt;/code&gt;是等价的，前者是HTML标签，后者是md语法。但是Pandoc并不能识别前者的HTML标签并转化成相应的Tex代码。所以从md到PDF的转化，不能夹杂HTML标签。&lt;/p&gt;
</description>
				<pubDate>Wed, 29 Apr 2015 07:25:06 +0800</pubDate>
				<link>http://badbye.github.io/badbye.github.com/2015/04/Rmd2pdf</link>
				<guid isPermaLink="true">http://badbye.github.io/badbye.github.com/2015/04/Rmd2pdf</guid>
			</item>
		
			<item>
				<title>Logistic Regression in R and Python</title>
				<description>&lt;p&gt;python中的scikit-learn库提供了一系列机器学习的算法，其中包括Logistic Regression。不过默认的，该库提供的是加入L2惩罚项的Logistic回归。但是程序设置上，python与R语言中有点出入，使得默认设置下同样数据出现的结果相差很大。&lt;/p&gt;

&lt;h2 id=&quot;r语言&quot;&gt;R语言&lt;/h2&gt;

&lt;p&gt;在R语言中执行带惩罚项的Logistic回归，需要加载glmnet包。包中Logistic回归的优化目标是：&lt;/p&gt;

&lt;p&gt;$$L(\theta)_R = -\frac{\text{log likelihood}}{\text{nobs}} + \lambda * \text{penalty}$$&lt;/p&gt;

&lt;p&gt;其中$\text{nobs}$代表样本量。惩罚项如果是L2惩罚，则是$\frac{1}{2} \parallel \theta \parallel_2^2$，其中不包含截距项。如果是L1惩罚，就是$|\theta|_1$.&lt;/p&gt;

&lt;p&gt;glmnet的设置：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;family=‘binomial’ 代表Logistic回归;&lt;/li&gt;
&lt;li&gt;alpha 表示elasticnet的混合参数：&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;$$\frac{1-\alpha}{2} \parallel \theta \parallel_2^2 + \alpha |\theta|_1$$&lt;/p&gt;

&lt;p&gt;所以$\alpha=1$表示lasso的L1惩罚，$\alpha=0$表示岭回归的L2惩罚;
lambda 就是优化目标中的参数λ
默认的，glmnet会添加截距项，并对自变量进行标准化。&lt;/p&gt;

&lt;h2 id=&quot;python&quot;&gt;python&lt;/h2&gt;

&lt;p&gt;python的scikit-learn中，Logistic回归是参考的&lt;a href=&quot;http://www.csie.ntu.edu.tw/%7Ecjlin/papers/maxent_dual.pdf&quot;&gt;这篇文献&lt;/a&gt;。文献中二阶惩罚优化的目标函数是：&lt;/p&gt;

&lt;p&gt;$$L(\theta) = -C*\text{log likelihood} + \frac{1}{2}\parallel \theta \parallel_2^2$$&lt;/p&gt;

&lt;p&gt;与R语言的区别在于，这里的惩罚项里包含截距项。另外参数设置上，这里的$C$相当于$\lambda$，都是作为一个权衡似然函数和惩罚项的参数。&lt;/p&gt;

&lt;p&gt;若想要与R语言的优化目标一致，则需要满足：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;不含截距项&lt;/li&gt;
&lt;li&gt;$n\lambda = \frac{1}{C}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;其中，$n$表示样本量，$\lambda$是R语言glmnet函数中的&lt;em&gt;lambda&lt;/em&gt;参数，$C$是python中的参数。&lt;/p&gt;

&lt;h2 id=&quot;code&quot;&gt;Code&lt;/h2&gt;

&lt;p&gt;选择iris数据的前100行，作一个二分类的Logistic回归。设置python中$C=1$，R语言中应该有$n\lambda=1$，所以&lt;em&gt;lambda&lt;/em&gt;应该是$\frac{1}{n}=0.01$。&lt;/p&gt;

&lt;h3 id=&quot;无截距项&quot;&gt;无截距项&lt;/h3&gt;

&lt;p&gt;python：无截距项&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_model&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_iris&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;logit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LogisticRegression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;tol&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fit_intercept&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;logit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coef_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;intercept_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;[array([[-0.44234418, -1.48544863,  2.23987714,  1.01147778]]), 0.0]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;R语言：无截距，不标准化&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;kn&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;glmnet&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
index &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;100&lt;/span&gt;
iris.x &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;as.matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;iris&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;index&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
iris.y &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;as.factor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;as.character&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;iris&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;index&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 不标准化自变量，不添加截距项&lt;/span&gt;
logit &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; glmnet&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;iris.x&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; iris.y&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; family&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;binomial&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; alpha&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; lambda&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; standardize&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; thresh &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1e-8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; intercept &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
coef&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;logit&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;5 x 1 sparse Matrix of class &amp;quot;dgCMatrix&amp;quot;
                     s0
(Intercept)   .        
Sepal.Length -0.4385104
Sepal.Width  -1.4868544
Petal.Length  2.2384771
Petal.Width   1.0031797
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;结果基本一致。&lt;/p&gt;

&lt;h3 id=&quot;添加截距项？&quot;&gt;添加截距项？&lt;/h3&gt;

&lt;p&gt;最后，若想添加截距项后两个程序结果一致，可以修改python中的&lt;code&gt;intercept_scaling&lt;/code&gt;参数，其参数解释为：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;when self.fit_intercept is True, instance vector x becomes [x, self.intercept_scaling], i.e. a “synthetic” feature with constant value equals to intercept_scaling is appended to the instance vector. The intercept becomes intercept_scaling * synthetic feature weight Note! the synthetic feature weight is subject to l1/l2 regularization as all other features. To lessen the effect of regularization on synthetic feature weight (and therefore on the intercept) intercept_scaling has to be increased.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;具体的计算原理不清楚，但依据解释，只要增大&lt;code&gt;intercept_scaling&lt;/code&gt;就可以减少惩罚项对截距的影响。&lt;/p&gt;

&lt;p&gt;先来看看python中添加截距项的默认结果：&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;logit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LogisticRegression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;tol&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fit_intercept&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;logit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coef_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;intercept_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;[array([[-0.4070443 , -1.46126494,  2.23984278,  1.00849909]]), array([-0.26042082])]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;增大intercept_scaling=100000的结果：&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;logit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LogisticRegression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;tol&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fit_intercept&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;intercept_scaling&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;logit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coef_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;intercept_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;[array([[-0.44234418, -1.48544863,  2.23987714,  1.01147778]]), 0.0]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;R语言中添加截距项的结果：&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;logit &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; glmnet&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;iris.x&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; iris.y&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; family&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;binomial&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; alpha&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; lambda&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
               standardize&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; thresh &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1e-8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; intercept &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
coef&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;logit&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;5 x 1 sparse Matrix of class &amp;quot;dgCMatrix&amp;quot;
                     s0
(Intercept)  -6.6114025
Sepal.Length  0.4403477
Sepal.Width  -0.9070024
Petal.Length  2.3084749
Petal.Width   0.9623247
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;增大&lt;code&gt;intercept_scaling=100000&lt;/code&gt;后与R语言的结果基本一致了。&lt;/p&gt;
</description>
				<pubDate>Wed, 29 Oct 2014 07:25:06 +0800</pubDate>
				<link>http://badbye.github.io/badbye.github.com/2014/10/Logistic%20Regression%20in%20R%20and%20Python</link>
				<guid isPermaLink="true">http://badbye.github.io/badbye.github.com/2014/10/Logistic%20Regression%20in%20R%20and%20Python</guid>
			</item>
		
			<item>
				<title>非参数统计</title>
				<description>&lt;p&gt;刚学了吴喜之老师的&amp;quot;非参数统计&amp;quot;这本书,文字居多公式较少,很适合我这样数学底子差,懒得去深究的人读。我的授课老师却似乎看不太习惯,觉得有点啰嗦,大概是搞数学的通病吧?&lt;/p&gt;

&lt;p&gt;我也是喜欢简洁优美的公式的,前提是得让我看懂这符号究竟在说什么。这对聪明绝顶的数学家来说简直太难了,数学家与数学家之间都常常看不懂对方的公式。至于教材的作者，他们肯定被Word里的公式编辑器搞的心力交瘁再没心情多说几句解释一下。一直这么学的授课老师，大部分也习惯了满本公式，讲不出更多。所以像吴老师这样能给我这种人讲懂的大师也是不多的，简直太少了。&lt;/p&gt;

&lt;p&gt;整本书唯一的缺陷大概就是代码不敢让人恭维了，吴老师毕竟不年轻了。但世界上总是不缺年轻人的，我就是一个。我的代码除了变量名起的很随便以及不加注释外，应该还算凑合。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://badbye.github.io/Non-parameter.single/&quot;&gt;非参统计之单样本检验&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://badbye.github.io/Non-parameter.two/&quot;&gt;非参统计之双样本检验&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://badbye.github.io/Non-parameter.mutiple/#1&quot;&gt;非参统计之多样本检验&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;如果你看不懂，那很正常，旁边放本教材才行。如果里边有错误，那也很正常，记得通知我修改，毕竟我不是Linus Torvalds。如果有更好的写法，那就更正常了，记得分享出来，我会很感谢你的。&lt;/p&gt;

&lt;p&gt;另:据说郑大10级的学弟学妹们也开了这门课，用的是王星的教材，工具也是R。他们授课老师是我毕业论文的导师，跟吴喜之老师同姓，跟我同名，容我牵强的说一句好有缘呐。&lt;/p&gt;
</description>
				<pubDate>Sat, 23 Nov 2013 07:25:06 +0800</pubDate>
				<link>http://badbye.github.io/badbye.github.com/2013/11/%E9%9D%9E%E5%8F%82%E6%95%B0%E7%BB%9F%E8%AE%A1</link>
				<guid isPermaLink="true">http://badbye.github.io/badbye.github.com/2013/11/%E9%9D%9E%E5%8F%82%E6%95%B0%E7%BB%9F%E8%AE%A1</guid>
			</item>
		
			<item>
				<title>第六届R语言会议记事</title>
				<description>&lt;p&gt;近两年着实走了不少地方，见了许多美丽风景，做了些许二逼趣事，但又似乎像背英语一样过目即忘。其实也不能说是忘了，只是一直没去想而已。有必要写写日记。&lt;/p&gt;

&lt;p&gt;继上次的古典骇客音乐会，这次的R语言会议是第二个让我感受到魔都大都市气息的地方。学术界和业界大牛云集，终于见到统计之都里李舰，魏太云，cloudy，魔王等真人风采。可惜两天报告下来能消化的倒不多。&lt;/p&gt;

&lt;h2 id=&quot;林智仁教授&quot;&gt;林智仁教授&lt;/h2&gt;

&lt;p&gt;之前在会议安排里看到几篇报告的摘要都是英文的，顿时觉得会不会太高端了些？第一个报告这位林教授连脚注里的简介都是英文的，以至于根本没细看。后来到现场才意识到这位就是libsvm包的开发者，瞬间崇拜万分。&lt;/p&gt;

&lt;p&gt;林教授以自身经历分享了编写机器学习和数据挖掘软件的经验，对我这毛头小子基本是没什么帮助的。通篇演讲也是中英混杂，好在之前有在coursera和网易修过机器学习的课，竟然都听懂了，不由的小得意一下。中间有讲到些模型改进的措施，比如数据的预处理，核函数的选择以及参数调整有借鉴之处。想起本科论文时的文本分类只简单做了稀疏矩阵的删减和核函数的选择，参数没调就扔进去跑了。结果训练集准确率98%，测试集只有85%左右，严重过拟合就那么交了，反正老师看不懂。真是惭愧惭愧…&lt;/p&gt;

&lt;h2 id=&quot;何通&quot;&gt;何通&lt;/h2&gt;

&lt;p&gt;这位就是当年在果壳写篇文章被老师拿去当考题的大神—严酷的魔王了，也是直到他的报告才知道魔王真相。分享了豆瓣标签数据的整理和分析，整场报告围绕一个主题层层递进，最符合我的审美观。&lt;/p&gt;

&lt;p&gt;豆瓣里音乐，电影等的标签是由用户自己打的，于是各种奇葩的标签层出不穷，需要先机器预处理再由工作人员手工操作，一来给产品加标签，二来给用户加标签，用于后期的推荐系统。&lt;/p&gt;

&lt;p&gt;基本的去噪分词倒是不难做的。但分词后数据量仍然不小，人工很难处理，于是就有了下边很有趣的基于关联规则的近义词处理。比如&amp;quot;惊悚&amp;quot;，“恐怖&amp;quot;和&amp;quot;悬疑&amp;quot;等标签表达意义相近，可以由机器直接转化为一个标签，省去不少麻烦。具体的算法大概就是计算一个条件概率，比如在对一部电影的描述中如果( P(词B出现|词A出现) )很大，就意味着A和B是对同一类事物的描述，含义相近。最后设置阈值使得大于某个值的条件概率所对应的两个词归为近义词。但是A和B相近同样意味着B和A相近，那相应的还有另一个条件概率( P(词A出现|词B出现) )呢，这个怎么处理倒没介绍，如果是我的话会选两者中比较大的概率，有机会要折腾一下。&lt;/p&gt;

&lt;p&gt;本来以为到这一步就结束，没想到后续还有一个标签的层次划分，给标签划分层次，比如&amp;quot;日本动漫&amp;quot;这一个标签下再划分有&amp;quot;热血”，“励志&amp;quot;等标签，这样一个类似树状图的东西，但各颗树又相互交叠，比如&amp;quot;军事电影&amp;quot;里同样会有&amp;quot;热血”，“励志&amp;quot;这样的标签，这样一层一层的划分出来，越上层的标签越抽象，越底层的越具体，之后可以尝试更有趣的推荐。对&amp;quot;励志&amp;quot;的&amp;quot;日本动漫&amp;quot;爱好者推荐其他的日本动漫，或者&amp;quot;军事电影&amp;quot;中励志电影，甚至跨越影视的界限推介些励志的书籍。相关的算法同样是计算条件概率的问题，如果( P(A|B) )很大但( P(B|A) )却很小就说B从属于A，因为B出现时A有很大概率出现反之却不然，说明A包含B。印象中就是这个样子了，总感觉哪里错了的样子，回头再瞅瞅幻灯片吧。&lt;/p&gt;

&lt;h2 id=&quot;李舰&quot;&gt;李舰&lt;/h2&gt;

&lt;p&gt;舰叔出品，必属精品。&lt;/p&gt;

&lt;p&gt;这次大会介绍了他的文本挖掘新包:tmcn。相对于之前的Rweibo和Rwordseg来说，新包发布好低调，之前竟然没听说一点消息。舰叔的博客也还没更新，附个安装方法:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;install.packages&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;tmcn&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; repos &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;http://R-Forge.R-project.org&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;此包主要用于中文的文本挖掘，提供了一些我觉得很有用的函数:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;toUTF8
无论是在windows里，还是linux下我都被中文的各种编码蹂躏过。网页里的编码&amp;quot;GBK”，“GBK2312&amp;quot;和&amp;quot;BIG5&amp;quot;等各种各样都有，知道它们是何种编码还好，可以用&lt;em&gt;iconv&lt;/em&gt;函数来转换。问题是大部分情况下系统不能识别编码我们也不知道，只能挨个尝试。现在好了，&lt;em&gt;toUTF8&lt;/em&gt;把一切中文字符转化为UTF8，任它千万变化，我只一招制敌!世界终于清静了…&lt;/li&gt;
&lt;li&gt;&lt;p&gt;toPinyin
这个函数把汉字转化为拼音，之所以有趣是因为另一个包&lt;em&gt;ggmap&lt;/em&gt;里有一个&lt;em&gt;geocode&lt;/em&gt;函数可以根据地址得到经纬度坐标，但变量只能是拼音，之前一直找把汉字转化为拼音的函数，现在终于有了。终于可以在地图上毫无压力的标注城市了。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;stopwordsCN
包含了503个中文的停止词，除了感动我还能说些什么？&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;另外这个包与tm包相比更方便使用，其数据格式还是原本的向量，矩阵，列表和数据框等，没有建立新的S3类。回想起第一次用tm包连建立和查看语料库都得翻一遍帮助文档，真是太辛酸了。&lt;/p&gt;

&lt;h2 id=&quot;陈逸波&quot;&gt;陈逸波&lt;/h2&gt;

&lt;p&gt;经常在统计之都的求助帖里见到一位ID名为波波头一头的大神回复&amp;quot;是这样嘛？(略去一行代码)”，然后我默默的打开R看看这个函数的帮助，欣喜的发现还有这么好使的函数。&lt;/p&gt;

&lt;p&gt;见到本人已经比微博和统计之都里的头像瘦多了，大概是经常跑步的缘故。回到正题。波波前辈分享了在kaggle实战的经验，在数据属性都不知道的前提下达到91%的预测准确率，受益良多。虽然说简单些就是了解数据，特征选取，建模和改进的过程，但过程之艰辛需要不断的尝试，假设，实验。终于稍微明白些什么叫对数据的敏感了。&lt;/p&gt;

&lt;h2 id=&quot;其他&quot;&gt;其他&lt;/h2&gt;

&lt;p&gt;第二位来自台湾的林祯舜教授，讲述了大数据对统计教育的影响，真应该上传视频让所有统计老师都听听的…&lt;/p&gt;

&lt;p&gt;ebay专场讲述了R在ebay的应用，包括了Rhipe和Rhadoop的介绍，终于知道这俩单词怎么发音了，同时也好像搭建个集群玩玩，嘛时候把宿舍四台电脑连起来跑跑2000W？另:感觉ebay的人都有种气场，如此牛逼的跨国公司就是这么的不一样么？附个做报告时被拍最多的ebay美女照片。 [不好意思，图片被我弄丢了╮(╯_╰)╭]&lt;/p&gt;

&lt;p&gt;会议之前就被echarts震撼到，各种交互式操作实在是忽悠人的最佳利器。可惜跟D3一样是个js库，想起暑假在菲律宾还学过几招D3，现在只能差不多看懂代码但写不出来了。好在魏太云和周扬开发了R的接口recharts，在R里也能方便的画出来了，还能跟shiny和knitr结合。前两天刚用shiny写完的web应用又要改了。&lt;/p&gt;

&lt;p&gt;多元作业的paper还没读，linux下的latex又要重新学。听两天报告就又给自己找这么多事儿，真是能自娱自乐。禁不住又要一声悠远深长的叹息，唉~~~&lt;/p&gt;
</description>
				<pubDate>Mon, 04 Nov 2013 07:25:06 +0800</pubDate>
				<link>http://badbye.github.io/badbye.github.com/2013/11/%E7%AC%AC%E5%85%AD%E5%B1%8AR%E8%AF%AD%E8%A8%80%E4%BC%9A%E8%AE%AE%E8%AE%B0%E4%BA%8B</link>
				<guid isPermaLink="true">http://badbye.github.io/badbye.github.com/2013/11/%E7%AC%AC%E5%85%AD%E5%B1%8AR%E8%AF%AD%E8%A8%80%E4%BC%9A%E8%AE%AE%E8%AE%B0%E4%BA%8B</guid>
			</item>
		
			<item>
				<title>$R^2$如何小于0？</title>
				<description>&lt;p&gt;偶然听说回归分析里，可决系数$R^2$可以小于0，未曾见过，不明觉厉。然细细斟酎后，倒也不过如此。&lt;/p&gt;

&lt;h2 id=&quot;调整前的-r-2&quot;&gt;调整前的$R^2$&lt;/h2&gt;

&lt;p&gt;一般来讲，$R^2 = 1-\frac{RSS}{TSS}$，其中$RSS=\sum{(y_i-\hat{y_i})^2}$表示残差平方和，$TSS=\sum{(y-\bar{y}^2)}$表示总离差平方和。若有$R^2&lt;0$，则须$\frac{RSS}{TSS}&gt;1$，即$RSS&amp;gt;TSS$。&lt;/p&gt;

&lt;p&gt;又有$TSS=RSS+ESS$，$ESS=\sum{(\hat{y_i}-\bar{y})}^2$，明显三者都是非负的，那么$RSS&amp;gt;TSS$是不可能了。&lt;/p&gt;

&lt;p&gt;问题在哪里？&lt;a href=&quot;http://cos.name/cn/topic/102862&quot;&gt;这个帖子&lt;/a&gt;里的一句话让我醍醐灌顶：$TSS=ESS+RSS$在无截距项时是不成立的！且再推导一遍方差分解的过程得到：&lt;/p&gt;

&lt;p&gt;$$TSS=RSS+ESS-2\bar{y}\sum{(y_i-\hat{y_i})}+2\beta\sum{(y_i-\hat{y_i})x_i}$$&lt;/p&gt;

&lt;p&gt;在有截距下的假设下，$Y=\beta_0+\beta_1X$，为最小化$TSS$，分别对$\beta_0$和$\beta_1$求偏导得到正规方程组：&lt;/p&gt;

&lt;p&gt;$$\sum{(y_i-\hat{y_i})x_i}=0$$
$$\sum{(y_i-\hat{y_i})}=0$$&lt;/p&gt;

&lt;p&gt;刚好方差分解式右端的两项都为0,便有了$TSS=RSS+ESS$。去掉截距项即去掉$\beta_0$，正规方程组便只剩下前式。之前的$TSS=ESS+RSS$变成：&lt;/p&gt;

&lt;p&gt;$$TSS=RSS+ESS-2\bar{y}\sum{(y_i-\hat{y_i})}$$&lt;/p&gt;

&lt;p&gt;如此一来，当$ESS-2\bar{y}\sum{(y_i-\hat{y_i})}&lt;0$时，有$RSS&gt;TSS$进而有$R^2&amp;lt;0$。&lt;/p&gt;

&lt;p&gt;另外，若用公式$\frac{ESS}{TSS}$计算$R^2$，当$RSS-2\bar{y}\sum{(y_i-\hat{y_i})}&lt;0$即$ESS&gt;TSS$时，便有$R^2&amp;gt;1$。&lt;/p&gt;

&lt;p&gt;最后，比较一下有无截距项的$R^2$，一般来讲，加一个截距项相当于增加一个变量，总是比不加要拟合的更好的，即有$RSS_{+} &amp;lt; RSS_{-}$，那么便有$R^2_{+} &amp;gt; R^2_{-}$。模拟一下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;kp&quot;&gt;set.seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;101&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
a &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;100&lt;/span&gt;
b &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;runif&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;kp&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;lm&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;b&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;a&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;r.squared
&lt;span class=&quot;kp&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;lm&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;b&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;a&lt;span class=&quot;m&quot;&gt;-1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;r.squared
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;0.9910709
0.997794
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;去掉截距项后$R^2$变大了？&lt;/p&gt;

&lt;p&gt;经查证仍然是无截距回归中$TSS \neq RSS+ESS$不等的问题，在$R$语言里无截距回归的$R^2$计算方式变成$\frac{RSS}{RSS+ESS}$，通常有$RSS+ESS&amp;gt;TSS$，分子分母都增大，这才&lt;strong&gt;可能&lt;/strong&gt;导致$R^2_-&amp;gt;R^2_+$。&lt;/p&gt;

&lt;h2 id=&quot;调整后的-r-2&quot;&gt;调整后的$R^2$&lt;/h2&gt;

&lt;p&gt;在多元情况下，需要对$R^2$进行调整，除以自由度，$R^2 = 1-\frac{RSS/p}{TSS/(n-p-1)}$。&lt;/p&gt;

&lt;p&gt;此时若要$R^2&lt;0$，则有$\frac{RSS/p}{TSS/(n-p-1)}&gt;1$，由于除了自由度，这时只需$n&amp;gt;&amp;gt;p$就&lt;strong&gt;可能&lt;/strong&gt;使得$\frac{RSS}{p}&amp;gt;\frac{TSS}{n-p-1}$。模拟一下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;kp&quot;&gt;set.seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;101&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
x1 &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10000&lt;/span&gt;
x2 &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; rnorm&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
y &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; rnorm&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;kp&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;lm&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;y&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;x1&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;x2&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-R&quot; data-lang=&quot;R&quot;&gt;&lt;span class=&quot;kp&quot;&gt;set.seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;101&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
x1 &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10000&lt;/span&gt;
x2 &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; rnorm&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
y &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; rnorm&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;kp&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;lm&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;y&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;x1&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;x2&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;Call:
lm(formula = y ~ x1 + x2)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.8688 -0.6775 -0.0251  0.6858  4.4694 

Coefficients:
              Estimate Std. Error t value Pr(&amp;gt;|t|)
(Intercept)  2.546e-02  1.986e-02   1.282    0.200
x1          -4.295e-06  3.440e-06  -1.249    0.212
x2           5.588e-03  1.000e-02   0.559    0.576

Residual standard error: 0.9931 on 9997 degrees of freedom
Multiple R-squared:  0.0001878,    Adjusted R-squared:  -1.219e-05 
F-statistic: 0.9391 on 2 and 9997 DF,  p-value: 0.391
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
				<pubDate>Thu, 19 Sep 2013 07:25:06 +0800</pubDate>
				<link>http://badbye.github.io/badbye.github.com/2013/09/$R%5E2$%E5%A6%82%E4%BD%95%E5%B0%8F%E4%BA%8E0%EF%BC%9F</link>
				<guid isPermaLink="true">http://badbye.github.io/badbye.github.com/2013/09/$R%5E2$%E5%A6%82%E4%BD%95%E5%B0%8F%E4%BA%8E0%EF%BC%9F</guid>
			</item>
		
			<item>
				<title>考研英语词频计算</title>
				<description>&lt;p&gt;按照大纲要求，考研英语需要识忆6000+个词汇，其中包含一批比较生僻的词汇。但大纲要求的单词不可能全部出现在试卷中，甚至有的可能根本就没出现过吧？如果真是这样，计算出频率较高的词汇，基础较差的孩子只需把握重点，有的放矢，应该能省不少功夫。其实算出来发现不用背6000+的，需要学的连2000都不到！&lt;/p&gt;

&lt;p&gt;介绍下步骤，先清洗掉一些你从来都不会去读的东西，比如标题，以及一些标点符号和数字等;然后删去没必要再学的单词，比如&amp;#39;a&amp;#39;，&amp;#39;the&amp;#39;;接下来还得去除词性变化，比如把&amp;#39;congrates&amp;#39;还原到&amp;#39;congrate&amp;#39;;最后再计算词频。简而言之就是大致经过四个阶段：数据清洗$\to$去除停止词$\to$词干化$\to$计算词频。&lt;/p&gt;

&lt;h2 id=&quot;一-数据清洗&quot;&gt;(一) 数据清洗&lt;/h2&gt;

&lt;p&gt;考研英语共分四部分：“section I Use of English”、“section II Reading Comprehension”、“section III Translation”和“section IV Writing”，这些标题以及其他语句如：“Read the following text. Choose the best word(s) for each numbered blank and mark A, B, C or D on ANSWER SHEET 1. (10 points)”在每年的试卷中都会出现，因此在统计词频之前应去除这些语句的干扰。&lt;/p&gt;

&lt;p&gt;此外文档中还存在除单词以外的其他干扰：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;每部分的标题号：Part A, B, C, D；&lt;/li&gt;
&lt;li&gt;阅读的题号：Text 1, 2, 3, 4；&lt;/li&gt;
&lt;li&gt;数字包括题号等；&lt;/li&gt;
&lt;li&gt;选项的标号：[A]到[G]；&lt;/li&gt;
&lt;li&gt;作文部分&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;选取&lt;a href=&quot;http://pan.baidu.com/s/1bnlQtqf&quot;&gt;2003—2013年的真题&lt;/a&gt;进行计算,对数据手工去除作文部分后，运用正则表达式将文档中的其他干扰去除。正则表达式是一种操作字符串的逻辑公式，可以通过它匹配到符合某个语法规则的字符，从而获取我们想要的特定部分。&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;text &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;readLines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;2003-2013考研英语真题.txt&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;## 清洗数据&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;require&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;stringr&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
text &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; str_trim&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;text&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;#去除字符串两端的空格&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 去除以‘section’；‘direction’;&amp;#39;reading the&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# following&amp;#39;;&amp;#39;part&amp;#39;,&amp;#39;text&amp;#39;开头的段落&lt;/span&gt;
text.clean &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;grep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;^section|^direction|read the following|part|text&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; text&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    perl &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; value &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; invert &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; ignore.case &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 去除选项[A]-[G]和字母以外的字符变为空格&lt;/span&gt;
text.clean &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;gsub&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;\\[[A-G]\\]|[^a-zA-Z]&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot; &amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; text.clean&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; perl &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; ignore.case &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
text.clean &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;paste&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;text.clean&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; collapse &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot; &amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;#连接文档&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 去除多余的空格和tab符、换行符等&lt;/span&gt;
text.clean &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;gsub&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot; +|\t|\n|\r&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot; &amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; text.clean&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&quot;二-停止词和词干化&quot;&gt;(二) 停止词和词干化&lt;/h2&gt;

&lt;h3 id=&quot;停止词&quot;&gt;停止词&lt;/h3&gt;

&lt;p&gt;完成第一次清洗后，文档还中包含众多“the”、“a”、“of”等词，这些都是最最简单而又最最常用的单词，不足以再花时间复习一下，因此需要第二次清洗，去除简单词汇。在网络搜索中有stop word即停止词的概念，很多词汇不可避免的要用到但又无实际意义或者非常普遍，那么在搜索排名时就不应将这些词的频率纳入算法计算的范围内。&lt;/p&gt;

&lt;p&gt;在各个领域停止词的定义不尽相同，在这里采用&lt;a href=&quot;http://pan.baidu.com/share/link?shareid=1488556438&amp;amp;uk=622761108&quot;&gt;新东方考研英语单词&lt;/a&gt;作为字典，其中包含3600左右的考研常用单词(已剔除简单单词)，故只需从文档中提取字典中的单词即可。&lt;/p&gt;

&lt;h3 id=&quot;词干化&quot;&gt;词干化&lt;/h3&gt;

&lt;p&gt;另一个问题就是：在英语中一个单词有多种形式，如like可以有likes,liking,liked等形式，其含义都是相同的，如《神雕侠侣》中的过儿和杨过、姑姑和小龙女都是指同一个人，所以在计算词频之前，需要再次对数据进行加工处理将其还原，这个过程称为词干化。SnowballC包提供了词干化功能，例：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;kn&quot;&gt;require&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;SnowballC&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
wordStem&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;liked&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;likes&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;liking&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;confuse&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;combine&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;[1] &amp;quot;like&amp;quot;   &amp;quot;like&amp;quot;   &amp;quot;like&amp;quot;   &amp;quot;confus&amp;quot; &amp;quot;combin&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;从例子中看出这个算法并不完美，对于“confuse”,“combine”以“e”结尾的单词强制去除“e”，效果并不理想。&lt;/p&gt;

&lt;p&gt;基于以上两个问题，如果直接从文档中提取字典中的词汇会忽略词汇的众多变化，将文档词干化后再与字典匹配会由于词干化算法的缺陷出现较大失误。&lt;/p&gt;

&lt;p&gt;不过如果两个词词干化后是一样的，那么这两个词有很大可能是同一个词的不同形式。因此一个较好的做法是将文档和字典同时词干化后再进行匹配统计，即将文档词干化后从中找到与字典中的词干相同的词汇。&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# 载入字典&lt;/span&gt;
dictionary &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;scan&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;新东方考研单词.txt&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; what &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;character&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 清洗字典中的不相干字符‘List 1-50’ (共50章)&lt;/span&gt;
dictionary &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; dictionary&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;grep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;List|\\d&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; dictionary&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; perl &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; invert &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 将字典词干化&lt;/span&gt;
dictionary.stem &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; wordStem&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;dictionary&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 计算词干重复的个数&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;repeat_stem &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;dictionary&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;unique&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;dictionary.stem&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;[1] 247
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;通过计算，对字典词干化后共有247个词汇词干化后与其他词汇相同，词干相同的前30个词是：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# 来看哪些词词干化之后是相同的 词干化之后各词的频率&lt;/span&gt;
dic.stem.fre &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;dictionary.stem&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 查找每个词干的频率&lt;/span&gt;
dic.fre &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;mapply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kr&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; dic.stem.fre&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;x&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; dictionary.stem&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 构造数据框并按频率排序&lt;/span&gt;
dic &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;data.frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;dictionary&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; dictionary.stem&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; dic.fre&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 按频率和字母排序&lt;/span&gt;
dic.order &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; dic&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;order&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;dic&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;dic.fre&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; dic&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;dictionary.stem&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; decreasing &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 查看前30个词干相同的词&lt;/span&gt;
&lt;span class=&quot;kp&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;dic.order&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; row.names &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;     dictionary dictionary.stem dic.fre
       organize           organ       5
        organic           organ       5
   organization           organ       5
          organ           organ       5
       organism           organ       5
       generate           gener       4
       generous           gener       4
     generalize           gener       4
      generator           gener       4
       critical          critic       4
      criticize          critic       4
         critic          critic       4
      criticism          critic       4
  correspondent      correspond       4
     correspond      correspond       4
 correspondence      correspond       4
  corresponding      correspond       4
      tolerance           toler       3
       tolerate           toler       3
       tolerate           toler       3
    responsible         respons       3
       response         respons       3
 responsibility         respons       3
         resist          resist       3
      resistant          resist       3
     resistance          resist       3
     prosperity         prosper       3
     prosperous         prosper       3
        prosper         prosper       3
      precedent          preced       3
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;最多有5个单词的词干相同，且词干相同的词汇都具有相同的词根因而具有相似的意义，如“organ”和“organic”均有器官的意思只是词性不同，而“organism”则由器官引申到有机体；“critical”，“criticize”均有批评挑剔的意思，只是词性不同，“critic”则是批评家的意思。其他不一一解释，可以看出词干相同的词汇，其含义大致相近。事实上这也是一种词汇记忆的方法 —词根记忆法，知道“critic”是批评家的意思，看到“critical”便可联想到批评。&lt;/p&gt;

&lt;p&gt;因此同时将文档和字典词干化后再匹配，将每个词的词频转换为计算其词干出现的频率， 由于词与词干的意义相似，误差并不大，是可行的。&lt;/p&gt;

&lt;h2 id=&quot;三-词干的词频&quot;&gt;(三) 词干的词频&lt;/h2&gt;

&lt;p&gt;如前文所述将文档词干化，首先转换格式变成一个词向量，然后汇总统计，最后词干化，这样可以保留每个词干所对应的词汇。&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;words &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;unlist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;strsplit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;text.clean&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot; &amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 分割文档&lt;/span&gt;
words.count &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;tolower&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;words&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 转换为小写并计数&lt;/span&gt;
words.data &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;data.frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;words.count&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 转换为数据框&lt;/span&gt;
&lt;span class=&quot;kp&quot;&gt;colnames&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;words.data&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;word&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;fre&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 更改列名&lt;/span&gt;
words.data&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;word &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;as.character&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;words.data&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;word&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
words.data&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;stem &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; wordStem&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;words.data&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;word&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 词干化&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;接下来从中取出与字典相对应的词干，即剔除停止词，并按词干的频率排序。&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# 将词干化后的文档对应到词干化后的字典&lt;/span&gt;
dic.stem &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;data.frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;stem &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;unique&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;dic.order&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;dictionary.stem&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
words.map &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;merge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;dic.stem&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; words.data&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
words.map &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; words.map&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;order&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;words.map&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;fre&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; decreasing &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 根据词频排序&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# 看看一共出现过多少个词汇&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;appear &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;unique&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;words.map&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;stem&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;[1] 1600
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# 看看有多少词汇未曾出现过&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;non_app &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;nrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;dic.stem&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; appear&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;[1] 1769
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;最后通过计算得到出现过的词汇个数，结果有点令人惊讶，新东方词汇共3619词，词干化后有3370个词干，而近十年的考研试卷中出现过的词干仅有1600个，未出现过的有1770个，这意味这有一半以上的词汇都未曾出现！看来《新东方考研英语单词》只需要背会一半就够了！&lt;/p&gt;

&lt;p&gt;那么，来看一下需要背哪一半。出现频率最高的30个词干是：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;kp&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;words.map&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; row.names &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;       stem         word fre
         be           be 241
         or           or 127
  paragraph    paragraph  74
     social       social  72
        out          out  54
     author       author  45
       like         like  39
     accord    according  38
     public       public  38
      state        state  37
       time         time  37
      feder      federal  35
       data         data  33
       educ    education  32
     inform  information  31
      human        human  30
     follow    following  29
   influenc    influence  28
      power        power  28
   intellig intelligence  26
      polit    political  26
      state       states  25
         be        being  24
     govern   government  24
     stress       stress  24
 intellectu intellectual  23
     nation     national  23
     consum    consumers  22
     differ    different  21
     econom     economic  21
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;结果有点意外，其中竟然包含了&amp;#39;be&amp;#39;,&amp;#39;like&amp;#39;,&amp;#39;time&amp;#39;,&amp;#39;data&amp;#39;,&amp;#39;human&amp;#39;,&amp;#39;power&amp;#39;,&amp;#39;find&amp;#39;这样的简单词汇，直觉上应该属于停止词。&lt;/p&gt;

&lt;p&gt;验证一下它们是否真的在字典里：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;kr&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;words &lt;span class=&quot;kr&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;be&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;like&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;time&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;data&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;human&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;power&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;find&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kp&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;dic.order&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;dic.order&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;dictionary.stem &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; words&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;kp&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;\n&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;     dictionary dictionary.stem dic.fre
1069      being              be       1

     dictionary dictionary.stem dic.fre
3331     likely            like       1

     dictionary dictionary.stem dic.fre
2373     timely            time       1

    dictionary dictionary.stem dic.fre
256       data            data       1

     dictionary dictionary.stem dic.fre
1489   humanity           human       1

    dictionary dictionary.stem dic.fre
898   powerful           power       1

     dictionary dictionary.stem dic.fre
3277    finding            find       1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;通过验证，“data”确实出现在字典中，而“be”则是“being”的词干，“find”是“finding”的词干，可见词干化后一些停止词趁虚而入了。果然英语文化也是博大精深，在词汇变化和一次多义方面令人很难琢磨（准确的说是令机器很难琢磨，或者令我难以琢磨，让我还没有找到一个有效的办法完全去除这些麻烦的停止词）。&lt;/p&gt;

&lt;p&gt;不过到这里倒不必吹毛求疵的人工去除停止词，就当是在提醒我们这些简单词的变化形式，比如“finding”不仅是“find”的现代分词，还有&amp;#39;发现物，研究结果&amp;#39;的意思。&lt;/p&gt;

&lt;h2 id=&quot;四-结果输出&quot;&gt;(四) 结果输出&lt;/h2&gt;

&lt;p&gt;将词干出现的频率汇总并由高到低排序，同时显示出词干化前的词汇及其相应的出现频率，写入一个文件方便查看。&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# 按词干汇总&lt;/span&gt;
stem.count &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; aggregate&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;fre &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; stem&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; data &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; words.map&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 排序&lt;/span&gt;
stem.count &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; stem.count&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;order&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;stem.count&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;fre&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; decreasing &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 查看频数最大的十个词干&lt;/span&gt;
&lt;span class=&quot;kp&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;stem.count&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;          stem fre
164         be 267
1012        or 127
1042 paragraph  82
1356    social  73
733      human  65
1389     state  65
880       like  59
143     author  56
1020       out  54
1177    public  50
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# 写出到文件 &lt;/span&gt;
&lt;span class=&quot;kr&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;i &lt;span class=&quot;kr&quot;&gt;in&lt;/span&gt; stem.count&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;stem&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  write.table&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;stem.count&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;stem.count&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;stem &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; i&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;words_fre.txt&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
              append&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; row.names&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; col.names&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
  write.table&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;words.data&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;words.data&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;stem&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;i&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;words_fre.txt&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
              append&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; row.names&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
  &lt;span class=&quot;kp&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;\n&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;words_fre.txt&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; append&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;已经写出来的文件words_fre.txt。&lt;/p&gt;

&lt;p&gt;最后，制作一个词云展示前100个高频词干(不是单词)：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;kn&quot;&gt;require&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;wordcloud&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## &amp;#39;be&amp;#39;这个单词出现次数远高于其他词汇，其他绘制出的单词都太小，故人工剔除&lt;/span&gt;
being_fre &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; stem.count&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;fre&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; words.map&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;fre&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;words.map&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;word &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;be&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
wordcloud&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;stem.count&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;stem&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; 
          &lt;span class=&quot;kt&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;being_fre&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; stem.count&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;fre&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt; 
          &lt;span class=&quot;kt&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;http://badbye.github.io/images/cloud.png&quot;/&gt;&lt;/p&gt;
</description>
				<pubDate>Sun, 15 Sep 2013 07:25:06 +0800</pubDate>
				<link>http://badbye.github.io/badbye.github.com/2013/09/%E8%80%83%E7%A0%94%E8%8B%B1%E8%AF%AD%E8%AF%8D%E9%A2%91%E8%AE%A1%E7%AE%97</link>
				<guid isPermaLink="true">http://badbye.github.io/badbye.github.com/2013/09/%E8%80%83%E7%A0%94%E8%8B%B1%E8%AF%AD%E8%AF%8D%E9%A2%91%E8%AE%A1%E7%AE%97</guid>
			</item>
		
	</channel>
</rss>
